"""
è«–æ–‡æ¢ç´¢ã®ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯
PubMed APIã¨Geminiè©•ä¾¡ã‚’çµ„ã¿åˆã‚ã›ã¦é–¢é€£è«–æ–‡ã‚’æ¢ç´¢
"""

from datetime import datetime
from typing import Dict, List, Callable, Optional, Set
from pubmed_api import PubMedAPI
from gemini_evaluator import GeminiEvaluator
from project_manager import Project
from openalex_api import OpenAlexAPI


class ArticleFinder:
    """è«–æ–‡æ¢ç´¢ã‚’è¡Œã†ã‚¯ãƒ©ã‚¹"""

    @staticmethod
    def get_article_id(article: Dict) -> str:
        """
        è«–æ–‡ã®ä¸€æ„ãªIDã‚’å–å¾—

        Args:
            article: è«–æ–‡æƒ…å ±ã®è¾æ›¸

        Returns:
            è«–æ–‡IDï¼ˆ"pmid:{pmid}" ã¾ãŸã¯ "doi:{doi}"ï¼‰
        """
        pmid = article.get("pmid")
        doi = article.get("doi")

        if pmid:
            return f"pmid:{pmid}"
        elif doi:
            return f"doi:{doi}"
        else:
            raise ValueError("Article must have either PMID or DOI")

    @staticmethod
    def add_article_id(article: Dict) -> Dict:
        """
        è«–æ–‡æƒ…å ±ã«ä¸€æ„ãªIDã‚’è¿½åŠ 

        Args:
            article: è«–æ–‡æƒ…å ±ã®è¾æ›¸

        Returns:
            IDãŒè¿½åŠ ã•ã‚ŒãŸè«–æ–‡æƒ…å ±
        """
        article["article_id"] = ArticleFinder.get_article_id(article)
        return article

    def __init__(
        self,
        gemini_api_key: Optional[str] = None,
        gemini_model: Optional[str] = None,
        notion_api_key: Optional[str] = None,
        notion_database_id: Optional[str] = None,
        openalex_email: Optional[str] = None
    ):
        """
        Args:
            gemini_api_key: Gemini API Keyï¼ˆçœç•¥æ™‚ã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ï¼‰
            gemini_model: ä½¿ç”¨ã™ã‚‹Geminiãƒ¢ãƒ‡ãƒ«åï¼ˆçœç•¥æ™‚ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«ï¼‰
            notion_api_key: Notion API Keyï¼ˆçœç•¥æ™‚ã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ã€æœªè¨­å®šã®å ´åˆNotioné€£æºã¯ç„¡åŠ¹ï¼‰
            notion_database_id: Notion Database IDï¼ˆçœç•¥æ™‚ã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ï¼‰
            openalex_email: OpenAlex Polite poolç”¨ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ï¼ˆçœç•¥æ™‚ã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ï¼‰
        """
        self.pubmed = PubMedAPI()
        self.evaluator = GeminiEvaluator(gemini_api_key, gemini_model)
        self.openalex = OpenAlexAPI(openalex_email)

        # Notion APIã‚’åˆæœŸåŒ–ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        self.notion = None
        if notion_api_key and notion_database_id:
            try:
                # é…å»¶import: Notioné€£æºã‚’ä½¿ã†å ´åˆã®ã¿import
                from notion_api import NotionAPI
                self.notion = NotionAPI(notion_api_key, notion_database_id)
            except ImportError:
                print("Notion API is not available. Install notion-client: pip install notion-client")
                self.notion = None
            except Exception as e:
                print(f"Notion API initialization failed: {e}")
                self.notion = None

    def find_articles(
        self,
        start_pmid_or_url: str,
        research_theme: str,
        max_depth: int = 2,
        max_articles: int = 500,
        relevance_threshold: int = 60,
        year_from: Optional[int] = None,
        include_similar: bool = True,
        max_similar: int = 20,
        include_cited_by: bool = True,
        max_cited_by: int = 20,
        include_references: bool = False,
        max_references: int = 20,
        pubmed_only: bool = False,
        progress_callback: Optional[Callable] = None,
        project: Optional[Project] = None,
        should_stop_callback: Optional[Callable] = None
    ) -> Dict:
        """
        è«–æ–‡ã‚’æ¢ç´¢ã—ã¦é–¢é€£è«–æ–‡ã‚’åé›†

        Args:
            start_pmid_or_url: èµ·ç‚¹ã¨ãªã‚‹è«–æ–‡ã®PMIDã¾ãŸã¯URL
            research_theme: ç ”ç©¶ãƒ†ãƒ¼ãƒï¼ˆè©³ç´°ãªèª¬æ˜ï¼‰
            max_depth: æ¢ç´¢ã®æ·±ã•ï¼ˆ1ä»¥ä¸Šï¼‰
            max_articles: åé›†ã™ã‚‹æœ€å¤§è«–æ–‡æ•°
            relevance_threshold: é–¢é€£æ€§ã‚¹ã‚³ã‚¢ã®é–¾å€¤ï¼ˆ0-100ï¼‰
            year_from: ã“ã®å¹´ä»¥é™ã®è«–æ–‡ã®ã¿ï¼ˆNoneã®å ´åˆã¯åˆ¶é™ãªã—ï¼‰
            include_similar: Similar articlesã‚’æ¢ç´¢ã™ã‚‹ã‹
            max_similar: Similar articlesã®æœ€å¤§å–å¾—æ•°ï¼ˆ1è«–æ–‡ã‚ãŸã‚Šï¼‰
            include_cited_by: Cited byã‚’æ¢ç´¢ã™ã‚‹ã‹
            max_cited_by: Cited byã®æœ€å¤§å–å¾—æ•°ï¼ˆ1è«–æ–‡ã‚ãŸã‚Šï¼‰
            include_references: Referencesã‚’æ¢ç´¢ã™ã‚‹ã‹
            max_references: Referencesã®æœ€å¤§å–å¾—æ•°ï¼ˆ1è«–æ–‡ã‚ãŸã‚Šï¼‰
            pubmed_only: PubMedåéŒ²è«–æ–‡ã®ã¿ã‚’å¯¾è±¡ã«ã™ã‚‹ï¼ˆDOIã®ã¿ã®è«–æ–‡ã‚’é™¤å¤–ï¼‰
            progress_callback: é€²æ—é€šçŸ¥ç”¨ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°
            project: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆï¼ˆæŒ‡å®šæ™‚ã¯é‡è¤‡ãƒã‚§ãƒƒã‚¯ã¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä½¿ç”¨ï¼‰
            should_stop_callback: åœæ­¢ãƒã‚§ãƒƒã‚¯ç”¨ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°ï¼ˆTrueã‚’è¿”ã™ã¨æ¢ç´¢ã‚’åœæ­¢ï¼‰

        Returns:
            {
                "articles": [è«–æ–‡æƒ…å ±ã®ãƒªã‚¹ãƒˆ],
                "stats": {
                    "total_found": int,
                    "total_evaluated": int,
                    "total_relevant": int,
                    "total_skipped": int,  # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ã®å–å¾—æ•°
                    "depth_reached": int
                },
                "interrupted": bool  # åœæ­¢ã«ã‚ˆã‚Šä¸­æ–­ã•ã‚ŒãŸå ´åˆTrue
            }
        """
        # èµ·ç‚¹PMIDã¾ãŸã¯DOIã‚’æŠ½å‡º
        start_pmid = self.pubmed.extract_pmid_from_url(start_pmid_or_url)
        start_doi = None
        start_identifier = None
        is_doi_start = False

        if start_pmid:
            # PMIDãŒã‚ã‚‹å ´åˆ
            start_identifier = start_pmid
            is_doi_start = False
        else:
            # PMIDãŒãªã„å ´åˆã€DOIã¨ã—ã¦æ‰±ã†
            start_doi = start_pmid_or_url.strip()
            start_identifier = start_doi
            is_doi_start = True

        if not start_identifier:
            raise ValueError(f"Invalid PMID or DOI: {start_pmid_or_url}")

        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã€æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        if project:
            # æ—¢å­˜ã®è«–æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            existing_articles = project.get_all_articles()
            self._notify_progress(
                progress_callback,
                f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‹ã‚‰æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ï¼ˆ{len(existing_articles)}ä»¶ï¼‰"
            )

        # åé›†æ¸ˆã¿è«–æ–‡ã‚’ç®¡ç†
        collected_articles: Dict[str, Dict] = {}
        visited_ids: Set[str] = set()  # "pmid:xxx" ã¾ãŸã¯ "doi:xxx" ã®å½¢å¼

        # çµ±è¨ˆæƒ…å ±
        stats = {
            "total_found": 0,
            "total_evaluated": 0,
            "total_relevant": 0,
            "total_skipped": 0,
            "depth_reached": 0,
            "session_article_count": 0  # ã“ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§è¿½åŠ ã•ã‚ŒãŸè«–æ–‡æ•°
        }

        # æ¤œç´¢ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã‚’ç”Ÿæˆï¼ˆã“ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§è¿½åŠ ã•ã‚Œã‚‹è«–æ–‡ã‚’è­˜åˆ¥ï¼‰
        session_id = datetime.now().isoformat()

        # èµ·ç‚¹è«–æ–‡ã‚’å‡¦ç†
        identifier_type = "DOI" if is_doi_start else "PMID"
        self._notify_progress(progress_callback, f"èµ·ç‚¹è«–æ–‡ã‚’å‡¦ç†ä¸­ ({identifier_type}: {start_identifier})")

        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        if project and project.has_article(start_identifier):
            self._notify_progress(progress_callback, f"èµ·ç‚¹è«–æ–‡ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—")
            start_article = project.get_article(start_identifier)

            # ã‚¹ã‚³ã‚¢ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ä½¿ç”¨ã™ã‚‹ãŒã€is_relevantã¯ç¾åœ¨ã®é–¾å€¤ã§å†è¨ˆç®—
            score = start_article.get("relevance_score", 0)
            start_article["is_relevant"] = score >= relevance_threshold

            # Article IDã‚’è¿½åŠ ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ãªã„å ´åˆã®ã¿ï¼‰
            if "article_id" not in start_article:
                article_id_prefix = "doi" if is_doi_start else "pmid"
                start_article["article_id"] = f"{article_id_prefix}:{start_identifier}"

            # ã‚½ãƒ¼ã‚¹æƒ…å ±ã‚’è¿½åŠ ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ãªã„å ´åˆã®ã¿ï¼‰
            if "source_pmid" not in start_article:
                start_article["source_pmid"] = None
                start_article["source_type"] = "èµ·ç‚¹è«–æ–‡"

            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—ã—ãŸã“ã¨ã‚’ç¤ºã™ãƒ•ãƒ©ã‚°
            start_article["is_newly_evaluated"] = False

            stats["total_skipped"] = 1
        else:
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ãªã„å ´åˆã¯å–å¾—ãƒ»è©•ä¾¡
            if is_doi_start:
                # DOIã®å ´åˆã¯OpenAlex APIã‹ã‚‰å–å¾—
                start_article = self.openalex.get_article_info_by_doi(start_identifier)
            else:
                # PMIDã®å ´åˆã¯PubMed APIã‹ã‚‰å–å¾—
                start_article = self.pubmed.get_article_info(start_identifier)

            if not start_article:
                raise ValueError(f"Failed to fetch article: {identifier_type} {start_identifier}")

            # èµ·ç‚¹è«–æ–‡ã‚’è©•ä¾¡
            self._notify_progress(progress_callback, f"èµ·ç‚¹è«–æ–‡ã‚’è©•ä¾¡ä¸­")

            try:
                evaluation = self.evaluator.evaluate_relevance(
                    research_theme,
                    start_article,
                    relevance_threshold
                )

                article_id_prefix = "doi" if is_doi_start else "pmid"
                start_article.update({
                    "article_id": f"{article_id_prefix}:{start_identifier}",  # ä¸€æ„ãªIDã‚’è¿½åŠ 
                    "relevance_score": evaluation["score"],
                    "is_relevant": evaluation["is_relevant"],
                    "relevance_reasoning": evaluation["reasoning"],
                    "depth": 0,
                    "source_pmid": None,
                    "source_type": "èµ·ç‚¹è«–æ–‡",
                    "mentioned_by": [],  # èµ·ç‚¹è«–æ–‡ã¯èª°ã‹ã‚‰ã‚‚å‚ç…§ã•ã‚Œã¦ã„ãªã„
                    "search_session_id": session_id,  # ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã‚’è¨˜éŒ²
                    "is_newly_evaluated": True  # æ–°è¦è©•ä¾¡ã•ã‚ŒãŸã“ã¨ã‚’ç¤ºã™ãƒ•ãƒ©ã‚°
                })

                stats["total_evaluated"] = 1
                stats["session_article_count"] += 1  # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚«ã‚¦ãƒ³ãƒˆã‚’å¢—ã‚„ã™

                # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ä¿å­˜ï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ä¿å­˜ï¼‰
                if project:
                    project.add_article(start_article)
                    project.save()
                    self._notify_progress(
                        progress_callback,
                        f"âœ… èµ·ç‚¹è«–æ–‡è©•ä¾¡å®Œäº†ãƒ»ä¿å­˜æ¸ˆã¿ (ã‚¹ã‚³ã‚¢: {evaluation['score']})"
                    )

            except Exception as e:
                # èµ·ç‚¹è«–æ–‡ã®è©•ä¾¡ã‚¨ãƒ©ãƒ¼ã¯è‡´å‘½çš„ãªã®ã§ã‚¨ãƒ©ãƒ¼ã‚’æŠ•ã’ã‚‹
                if project:
                    # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚ã€ã“ã“ã¾ã§ã®é€²æ—ã‚’ä¿å­˜
                    project.save()
                    self._notify_progress(
                        progress_callback,
                        f"ğŸ’¾ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸãŒã€é€²æ—ã‚’ä¿å­˜ã—ã¾ã—ãŸ"
                    )
                raise ValueError(f"èµ·ç‚¹è«–æ–‡ã®è©•ä¾¡ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")

        start_article_id = f"pmid:{start_pmid}"
        collected_articles[start_article_id] = start_article
        visited_ids.add(start_article_id)
        stats["total_found"] = 1
        if start_article.get("is_relevant"):
            stats["total_relevant"] = 1

        # æ·±ã•å„ªå…ˆã§æ¢ç´¢
        # èµ·ç‚¹è«–æ–‡ã¯è©•ä¾¡ã‚¹ã‚³ã‚¢ã«é–¢ã‚ã‚‰ãšã€å¿…ãšæ¬¡ã®éšå±¤ã¸é€²ã‚€
        current_layer = [start_pmid]

        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã«å‡ºåŠ›
        print(f"\n{'='*60}")
        print(f"[DEBUG] æ¢ç´¢é–‹å§‹")
        print(f"  èµ·ç‚¹PMID: {start_pmid}")
        print(f"  max_depth: {max_depth}")
        print(f"  max_articles: {max_articles}")
        print(f"  include_similar: {include_similar}, max_similar: {max_similar}")
        print(f"  include_cited_by: {include_cited_by}, max_cited_by: {max_cited_by}")
        print(f"  include_references: {include_references}, max_references: {max_references}")
        print(f"  current_layer: {current_layer}")
        print(f"{'='*60}\n")

        for depth in range(1, max_depth + 1):
            print(f"\n[DEBUG] æ¢ç´¢éšå±¤ {depth}/{max_depth} é–‹å§‹")
            print(f"  current_layer: {current_layer}")
            print(f"  collected_articles: {len(collected_articles)}ä»¶")

            # åœæ­¢ãƒã‚§ãƒƒã‚¯
            if should_stop_callback and should_stop_callback():
                print(f"[DEBUG] åœæ­¢ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å—ã‘ä»˜ã‘ã¾ã—ãŸ")
                self._notify_progress(progress_callback, "åœæ­¢ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å—ã‘ä»˜ã‘ã¾ã—ãŸ")

                # æ¤œç´¢çŠ¶æ…‹ã‚’ä¿å­˜
                if project:
                    search_state = {
                        "start_pmid": start_pmid,
                        "research_theme": research_theme,
                        "session_id": session_id,
                        "current_layer": current_layer,
                        "current_depth": depth,
                        "visited_ids": list(visited_ids),
                        "collected_articles": collected_articles,
                        "stats": stats,
                        "settings": {
                            "max_depth": max_depth,
                            "max_articles": max_articles,
                            "relevance_threshold": relevance_threshold,
                            "year_from": year_from,
                            "include_similar": include_similar,
                            "max_similar": max_similar,
                            "include_cited_by": include_cited_by,
                            "max_cited_by": max_cited_by,
                            "include_references": include_references,
                            "max_references": max_references,
                            "pubmed_only": pubmed_only
                        }
                    }
                    project.save_search_state(search_state)
                    self._notify_progress(progress_callback, "æ¤œç´¢çŠ¶æ…‹ã‚’ä¿å­˜ã—ã¾ã—ãŸ")

                # ä¸­æ–­ãƒ•ãƒ©ã‚°ã‚’ç«‹ã¦ã¦çµ‚äº†
                return {
                    "articles": list(collected_articles.values()),
                    "stats": stats,
                    "interrupted": True
                }

                break

            if not current_layer:
                print(f"[DEBUG] current_layerãŒç©ºã®ãŸã‚çµ‚äº†")
                break

            if len(collected_articles) >= max_articles:
                print(f"[DEBUG] max_articlesåˆ°é”ã®ãŸã‚çµ‚äº†")
                break

            stats["depth_reached"] = depth

            self._notify_progress(
                progress_callback,
                f"æ¢ç´¢éšå±¤ {depth}/{max_depth} ã‚’é–‹å§‹ (å¯¾è±¡è«–æ–‡æ•°: {len(current_layer)})"
            )

            # æ¬¡ã®éšå±¤ã®å€™è£œã‚’å–å¾—
            next_layer = self._explore_layer(
                pmids=current_layer,
                research_theme=research_theme,
                depth=depth,
                visited_ids=visited_ids,
                collected_articles=collected_articles,
                max_articles=max_articles,
                relevance_threshold=relevance_threshold,
                year_from=year_from,
                include_similar=include_similar,
                max_similar=max_similar,
                include_cited_by=include_cited_by,
                max_cited_by=max_cited_by,
                include_references=include_references,
                max_references=max_references,
                pubmed_only=pubmed_only,
                progress_callback=progress_callback,
                stats=stats,
                project=project,
                should_stop_callback=should_stop_callback,
                session_id=session_id  # ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã‚’æ¸¡ã™
            )

            current_layer = next_layer

        # çµæœã‚’æ•´å½¢
        articles_list = list(collected_articles.values())

        # é–¢é€£æ€§ã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆ
        articles_list.sort(key=lambda x: x.get("relevance_score", 0), reverse=True)

        # Notioné€£æºï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰- æ–°è¦è©•ä¾¡ã•ã‚ŒãŸè«–æ–‡ã®ã¿
        if self.notion:
            # æ–°è¦è©•ä¾¡ã•ã‚ŒãŸè«–æ–‡ã®ã¿ã‚’æŠ½å‡º
            newly_evaluated_articles = [
                a for a in articles_list
                if a.get("is_newly_evaluated", False)
            ]

            if newly_evaluated_articles:
                self._notify_progress(
                    progress_callback,
                    f"æ–°è¦è©•ä¾¡ã•ã‚ŒãŸ {len(newly_evaluated_articles)} ä»¶ã®è«–æ–‡ã‚’Notionãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã§ãƒã‚§ãƒƒã‚¯ä¸­..."
                )
                try:
                    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåã‚’å–å¾—
                    project_name = project.metadata.get('name') if project else None

                    updated_articles = self.notion.batch_check_articles(
                        newly_evaluated_articles,
                        update_score=True,
                        callback=lambda current, total, pmid: self._notify_progress(
                            progress_callback,
                            f"Notionãƒã‚§ãƒƒã‚¯ä¸­ {current}/{total} (PMID: {pmid})"
                        ),
                        project_name=project_name,
                        research_theme=research_theme
                    )
                    self._notify_progress(progress_callback, "Notionãƒã‚§ãƒƒã‚¯å®Œäº†")

                    # æ›´æ–°ã•ã‚ŒãŸè«–æ–‡æƒ…å ±ã‚’articles_listã«åæ˜ 
                    pmid_to_updated = {a.get("pmid"): a for a in updated_articles}
                    for i, article in enumerate(articles_list):
                        pmid = article.get("pmid")
                        if pmid in pmid_to_updated:
                            articles_list[i] = pmid_to_updated[pmid]

                    # Notionæƒ…å ±ã‚’ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«åæ˜ 
                    if project:
                        for article in updated_articles:
                            project.add_article(article)
                        self._notify_progress(progress_callback, "Notionæƒ…å ±ã‚’ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ä¿å­˜ã—ã¾ã—ãŸ")
                except Exception as e:
                    self._notify_progress(progress_callback, f"Notionãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
            else:
                self._notify_progress(progress_callback, "æ–°è¦è©•ä¾¡ã•ã‚ŒãŸè«–æ–‡ãŒãªã„ãŸã‚ã€Notionãƒã‚§ãƒƒã‚¯ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸ")

        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’ä¿å­˜
        if project:
            # æ¤œç´¢ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã‚’è¿½åŠ 
            if stats["session_article_count"] > 0:
                project.add_search_session(session_id, stats["session_article_count"])

            project.save()
            self._notify_progress(progress_callback, "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ")

            # æ¤œç´¢å®Œäº†æ™‚ã¯ä¿å­˜ã•ã‚ŒãŸçŠ¶æ…‹ã‚’ã‚¯ãƒªã‚¢
            project.clear_search_state()

        return {
            "articles": articles_list,
            "stats": stats,
            "interrupted": False
        }

    def _explore_layer(
        self,
        pmids: List[str],
        research_theme: str,
        depth: int,
        visited_ids: Set[str],
        collected_articles: Dict[str, Dict],
        max_articles: int,
        relevance_threshold: int,
        year_from: Optional[int],
        include_similar: bool,
        max_similar: int,
        include_cited_by: bool,
        max_cited_by: int,
        include_references: bool,
        max_references: int,
        pubmed_only: bool,
        progress_callback: Optional[Callable],
        stats: Dict,
        project: Optional[Project],
        should_stop_callback: Optional[Callable] = None,
        session_id: str = None
    ) -> List[str]:
        """
        1éšå±¤åˆ†ã®æ¢ç´¢ã‚’å®Ÿè¡Œ

        Returns:
            æ¬¡ã®éšå±¤ã§æ¢ç´¢ã™ã¹ãPMIDã®ãƒªã‚¹ãƒˆ
        """
        print(f"\n[DEBUG] _explore_layer é–‹å§‹")
        print(f"  å‡¦ç†ã™ã‚‹PMIDæ•°: {len(pmids)}")
        print(f"  PMIDs: {pmids}")
        print(f"  include_similar={include_similar}, max_similar={max_similar}")
        print(f"  include_cited_by={include_cited_by}, max_cited_by={max_cited_by}")
        print(f"  include_references={include_references}, max_references={max_references}")

        next_layer_pmids = []

        for i, identifier in enumerate(pmids):
            # identifierãŒPMIDã‹DOIã‹ã‚’åˆ¤å®š
            is_doi_identifier = identifier.startswith("10.")

            # è¦ªè«–æ–‡ã®article_idã‚’ç”Ÿæˆï¼ˆmentioned_byè¨˜éŒ²ç”¨ï¼‰
            parent_article_id = f"doi:{identifier}" if is_doi_identifier else f"pmid:{identifier}"

            if is_doi_identifier:
                print(f"\n[DEBUG] è«–æ–‡ {i+1}/{len(pmids)}: DOI {identifier} ã‚’å‡¦ç†ä¸­")
                self._notify_progress(
                    progress_callback,
                    f"DOI {identifier} ã®é–¢é€£è«–æ–‡ã‚’å–å¾—ä¸­"
                )
            else:
                print(f"\n[DEBUG] è«–æ–‡ {i+1}/{len(pmids)}: PMID {identifier} ã‚’å‡¦ç†ä¸­")
                self._notify_progress(
                    progress_callback,
                    f"PMID {identifier} ã®é–¢é€£è«–æ–‡ã‚’å–å¾—ä¸­"
                )

            # åœæ­¢ãƒã‚§ãƒƒã‚¯
            if should_stop_callback and should_stop_callback():
                self._notify_progress(progress_callback, "åœæ­¢ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å—ã‘ä»˜ã‘ã¾ã—ãŸ")
                break

            # æœ€å¤§ä»¶æ•°ãƒã‚§ãƒƒã‚¯
            if len(collected_articles) >= max_articles:
                self._notify_progress(
                    progress_callback,
                    f"æœ€å¤§è«–æ–‡æ•° {max_articles} ã«åˆ°é”ã—ã¾ã—ãŸ"
                )
                break

            # é–¢é€£è«–æ–‡ã‚’å–å¾—ï¼ˆã‚½ãƒ¼ã‚¹æƒ…å ±ã‚‚å«ã‚€ï¼‰
            # é–¢é€£è«–æ–‡ã®ãƒªã‚¹ãƒˆ: (identifier, source_type, extra_doi, is_doi_only) ã®ã‚¿ãƒ—ãƒ«ã®ãƒªã‚¹ãƒˆ
            # identifier: PMID ã¾ãŸã¯ DOI
            # extra_doi: OpenAlexã‹ã‚‰å–å¾—ã—ãŸDOIï¼ˆPMIDã‚ã‚Šã®å ´åˆã®ã¿ï¼‰
            # is_doi_only: DOIã®ã¿ã®è«–æ–‡ã‹ã©ã†ã‹
            related_pmids_with_source = []

            print(f"  [DEBUG] é–¢é€£è«–æ–‡å–å¾—é–‹å§‹")

            # Similar articlesï¼ˆPMIDã®å ´åˆã®ã¿ï¼‰
            if include_similar and not is_doi_identifier:
                similar = self.pubmed.get_related_articles(identifier, "similar")
                # åˆ¶é™æ•°ã¾ã§åˆ‡ã‚Šè©°ã‚
                related_pmids_with_source.extend([(p, "similar", None, False) for p in similar[:max_similar]])
                print(f"    Similar articles: {len(similar)} ä»¶ä¸­ {len(similar[:max_similar])} ä»¶å–å¾—")
                self._notify_progress(progress_callback, f"  Similar articles: {len(similar[:max_similar])} ä»¶å–å¾—")
            elif include_similar and is_doi_identifier:
                print(f"    Similar articles: DOIã®ã¿ã®è«–æ–‡ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—")

            # Cited byï¼ˆPMIDã¾ãŸã¯DOIï¼‰
            if include_cited_by:
                # OpenAlexã‹ã‚‰Cited byã‚’å–å¾—ï¼ˆDOIãŒã‚ã‚‹å…¨ã¦ã®æ–‡çŒ®ï¼‰
                if is_doi_identifier:
                    cited_by = self.openalex.get_cited_by_by_doi(identifier, limit=max_cited_by)
                else:
                    cited_by = self.openalex.get_cited_by_by_pmid(identifier, limit=max_cited_by)
                # åˆ¶é™æ•°ã¾ã§åˆ‡ã‚Šè©°ã‚
                for cite in cited_by[:max_cited_by]:
                    cite_pmid = cite.get("pmid")
                    cite_doi = cite.get("doi")

                    if cite_pmid:
                        # PMIDãŒã‚ã‚‹å ´åˆ
                        related_pmids_with_source.append((cite_pmid, "cited_by", cite_doi, False))
                    elif cite_doi:
                        # DOIã®ã¿ã®å ´åˆ
                        related_pmids_with_source.append((cite_doi, "cited_by", None, True))

                print(f"    Cited by: {len(cited_by)} ä»¶ä¸­ {len(cited_by[:max_cited_by])} ä»¶å–å¾—")
                self._notify_progress(progress_callback, f"  Cited by: {len(cited_by[:max_cited_by])} ä»¶å–å¾—")

            # Referencesï¼ˆPMIDã¾ãŸã¯DOIï¼‰
            if include_references:
                # OpenAlexã‹ã‚‰Referencesã‚’å–å¾—ï¼ˆDOIãŒã‚ã‚‹å…¨ã¦ã®æ–‡çŒ®ï¼‰
                if is_doi_identifier:
                    references = self.openalex.get_references_by_doi(identifier)
                else:
                    references = self.openalex.get_references_by_pmid(identifier)
                # åˆ¶é™æ•°ã¾ã§åˆ‡ã‚Šè©°ã‚
                for ref in references[:max_references]:
                    ref_pmid = ref.get("pmid")
                    ref_doi = ref.get("doi")

                    if ref_pmid:
                        # PMIDãŒã‚ã‚‹å ´åˆ
                        related_pmids_with_source.append((ref_pmid, "references", ref_doi, False))
                    elif ref_doi:
                        # DOIã®ã¿ã®å ´åˆ
                        related_pmids_with_source.append((ref_doi, "references", None, True))

                pmid_count = len([r for r in references[:max_references] if r.get("pmid")])
                doi_only_count = len([r for r in references[:max_references] if not r.get("pmid") and r.get("doi")])
                print(f"    References (OpenAlex): {len(references)} ä»¶ä¸­ {len(references[:max_references])} ä»¶å–å¾— (PMID: {pmid_count}, DOIã®ã¿: {doi_only_count})")
                self._notify_progress(progress_callback, f"  References: {len(references[:max_references])} ä»¶å–å¾—")

            print(f"  [DEBUG] åˆè¨ˆ {len(related_pmids_with_source)} ä»¶ã®é–¢é€£è«–æ–‡ã‚’å–å¾—")

            # é‡è¤‡å‰Šé™¤ï¼ˆåŒã˜IDã§ã‚‚ã‚½ãƒ¼ã‚¹ãŒç•°ãªã‚‹å ´åˆã€æœ€åˆã®ã‚‚ã®ã®ã¿ä¿æŒï¼‰
            seen_ids = set()
            unique_related = []
            for identifier, source_type, extra_doi, is_doi_only in related_pmids_with_source:
                # IDã‚’ç”Ÿæˆ
                if is_doi_only:
                    article_id = f"doi:{identifier}"
                else:
                    article_id = f"pmid:{identifier}"

                if article_id not in seen_ids:
                    seen_ids.add(article_id)
                    unique_related.append((identifier, source_type, extra_doi, is_doi_only))

            related_pmids_with_source = unique_related

            # æœªè¨ªå•ã®è«–æ–‡ã®ã¿å‡¦ç†
            new_pmids_with_source = []
            for identifier, source_type, extra_doi, is_doi_only in related_pmids_with_source:
                article_id = f"doi:{identifier}" if is_doi_only else f"pmid:{identifier}"
                if article_id not in visited_ids:
                    new_pmids_with_source.append((identifier, source_type, extra_doi, is_doi_only))

            print(f"  [DEBUG] æœªè¨ªå•ã®è«–æ–‡: {len(new_pmids_with_source)} ä»¶")
            if len(new_pmids_with_source) > 0:
                print(f"    æœ€åˆã®5ä»¶: {[id for id, _, _, _ in new_pmids_with_source[:5]]}")

            self._notify_progress(
                progress_callback,
                f"æ–°è¦è«–æ–‡ {len(new_pmids_with_source)} ä»¶ã‚’ç™ºè¦‹"
            )

            stats["total_found"] += len(new_pmids_with_source)

            # å„è«–æ–‡ã‚’å–å¾—ãƒ»è©•ä¾¡
            for identifier, source_type, openalex_doi, is_doi_only in new_pmids_with_source:
                # PubMedåéŒ²è«–æ–‡ã®ã¿ã‚’å¯¾è±¡ã«ã™ã‚‹å ´åˆã€DOIã®ã¿ã®è«–æ–‡ã¯ã‚¹ã‚­ãƒƒãƒ—
                if pubmed_only and is_doi_only:
                    print(f"  [DEBUG] PubMedã®ã¿ãƒ¢ãƒ¼ãƒ‰: DOI {identifier} ã‚’ã‚¹ã‚­ãƒƒãƒ—")
                    continue

                # åœæ­¢ãƒã‚§ãƒƒã‚¯
                if should_stop_callback and should_stop_callback():
                    self._notify_progress(progress_callback, "åœæ­¢ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å—ã‘ä»˜ã‘ã¾ã—ãŸ")
                    break

                if len(collected_articles) >= max_articles:
                    break

                # Article IDã‚’ç”Ÿæˆ
                article_id = f"doi:{identifier}" if is_doi_only else f"pmid:{identifier}"
                visited_ids.add(article_id)

                # è¡¨ç¤ºç”¨ã®è­˜åˆ¥å­
                display_id = f"DOI:{identifier}" if is_doi_only else f"PMID:{identifier}"

                # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                if project and project.has_article_by_id(article_id):
                    self._notify_progress(
                        progress_callback,
                        f"{display_id} ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾— ({len(collected_articles)}/{max_articles})"
                    )
                    article = project.get_article_by_id(article_id)

                    # ã‚¹ã‚³ã‚¢ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ä½¿ç”¨ã™ã‚‹ãŒã€is_relevantã¯ç¾åœ¨ã®é–¾å€¤ã§å†è¨ˆç®—
                    score = article.get("relevance_score", 0)
                    article["is_relevant"] = score >= relevance_threshold

                    # DOIæƒ…å ±ã‚’è£œå®Œï¼ˆOpenAlexã‹ã‚‰å–å¾—ã—ãŸDOIãŒã‚ã‚Šã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«DOIãŒãªã„å ´åˆï¼‰
                    if openalex_doi and not article.get("doi"):
                        article["doi"] = openalex_doi

                    # ã‚½ãƒ¼ã‚¹æƒ…å ±ã‚’è¿½åŠ ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ãªã„å ´åˆã®ã¿ï¼‰
                    if "source_pmid" not in article:
                        article["source_pmid"] = identifier
                        article["source_type"] = source_type

                    # mentioned_byã‚’æ›´æ–°ï¼ˆé‡è¤‡æ™‚ã‚‚è¦ªã‚’è¿½è¨˜ï¼‰
                    mentioned_by = article.get("mentioned_by", [])
                    if not isinstance(mentioned_by, list):
                        mentioned_by = []
                    if parent_article_id not in mentioned_by:
                        mentioned_by.append(parent_article_id)
                        article["mentioned_by"] = mentioned_by
                        # mentioned_byæ›´æ–°ã¯å¿…ãšä¿å­˜
                        if project:
                            project.add_article(article)
                            project.save()
                            print(f"    {display_id} ã® mentioned_by ã‚’æ›´æ–°: {parent_article_id} ã‚’è¿½åŠ ")

                    # æ—¥æœ¬èªè¦ç´„ãŒãªã„å ´åˆã¯ç”Ÿæˆ
                    if "abstract_summary_ja" not in article or not article.get("abstract_summary_ja"):
                        abstract = article.get("abstract", "")
                        title = article.get("title", "")
                        if abstract:
                            try:
                                abstract_summary_ja = self.evaluator.summarize_abstract(abstract, title)
                                article["abstract_summary_ja"] = abstract_summary_ja
                                # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ä¿å­˜
                                if project:
                                    project.add_article(article)
                                    project.save()
                            except Exception as e:
                                print(f"è¦ç´„ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
                                article["abstract_summary_ja"] = "è¦ç´„ç”Ÿæˆã‚¨ãƒ©ãƒ¼"
                        else:
                            article["abstract_summary_ja"] = "ã‚¢ãƒ–ã‚¹ãƒˆãƒ©ã‚¯ãƒˆãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚"

                    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—ã—ãŸã“ã¨ã‚’ç¤ºã™ãƒ•ãƒ©ã‚°
                    article["is_newly_evaluated"] = False

                    stats["total_skipped"] += 1
                else:
                    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ãªã„å ´åˆã¯å–å¾—ãƒ»è©•ä¾¡
                    # è«–æ–‡æƒ…å ±ã‚’å–å¾—
                    if is_doi_only:
                        # DOIã®ã¿ã®å ´åˆã¯OpenAlex APIã‹ã‚‰å–å¾—
                        article = self.openalex.get_article_info_by_doi(identifier)
                    else:
                        # PMIDãŒã‚ã‚‹å ´åˆã¯PubMed APIã‹ã‚‰å–å¾—
                        article = self.pubmed.get_article_info(identifier)

                    if not article:
                        continue

                    # DOIæƒ…å ±ã‚’è£œå®Œï¼ˆOpenAlexã‹ã‚‰å–å¾—ã—ãŸDOIãŒã‚ã‚Šã€PubMedã®DOIãŒãªã„å ´åˆï¼‰
                    if not is_doi_only and openalex_doi and not article.get("doi"):
                        article["doi"] = openalex_doi

                    # å¹´ãƒ•ã‚£ãƒ«ã‚¿
                    if year_from and article.get("pub_year"):
                        if article["pub_year"] < year_from:
                            continue

                    # é–¢é€£æ€§ã‚’è©•ä¾¡
                    self._notify_progress(
                        progress_callback,
                        f"{display_id} ã‚’è©•ä¾¡ä¸­ ({len(collected_articles)}/{max_articles})"
                    )

                    try:
                        evaluation = self.evaluator.evaluate_relevance(
                            research_theme,
                            article,
                            relevance_threshold
                        )

                        # ã‚¢ãƒ–ã‚¹ãƒˆãƒ©ã‚¯ãƒˆã®æ—¥æœ¬èªè¦ç´„ã‚’ç”Ÿæˆ
                        abstract = article.get("abstract", "")
                        title = article.get("title", "")
                        if abstract:
                            abstract_summary_ja = self.evaluator.summarize_abstract(abstract, title)
                        else:
                            abstract_summary_ja = "ã‚¢ãƒ–ã‚¹ãƒˆãƒ©ã‚¯ãƒˆãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚"

                        stats["total_evaluated"] += 1
                        stats["session_article_count"] += 1  # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚«ã‚¦ãƒ³ãƒˆã‚’å¢—ã‚„ã™

                        # è«–æ–‡æƒ…å ±ã‚’æ›´æ–°
                        article.update({
                            "article_id": article_id,  # ä¸€æ„ãªIDã‚’è¿½åŠ 
                            "relevance_score": evaluation["score"],
                            "is_relevant": evaluation["is_relevant"],
                            "relevance_reasoning": evaluation["reasoning"],
                            "abstract_summary_ja": abstract_summary_ja,  # æ—¥æœ¬èªè¦ç´„ã‚’è¿½åŠ 
                            "depth": depth,
                            "source_pmid": identifier,
                            "source_type": source_type,
                            "mentioned_by": [parent_article_id],  # è¦ªè«–æ–‡ã®IDã‚’è¨˜éŒ²
                            "search_session_id": session_id,  # ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã‚’è¨˜éŒ²
                            "is_newly_evaluated": True  # æ–°è¦è©•ä¾¡ã•ã‚ŒãŸã“ã¨ã‚’ç¤ºã™ãƒ•ãƒ©ã‚°
                        })

                        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ä¿å­˜ï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ä¿å­˜ï¼‰
                        if project:
                            project.add_article(article)
                            project.save()  # å„è«–æ–‡è©•ä¾¡å¾Œã«å³åº§ã«ä¿å­˜
                            self._notify_progress(
                                progress_callback,
                                f"âœ… {display_id} è©•ä¾¡å®Œäº†ãƒ»ä¿å­˜æ¸ˆã¿ (ã‚¹ã‚³ã‚¢: {evaluation['score']}, ä¿å­˜æ¸ˆã¿: {len(collected_articles) + 1}ä»¶)"
                            )

                    except Exception as e:
                        # è©•ä¾¡ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚è«–æ–‡æƒ…å ±ã¯ä¿å­˜ï¼ˆã‚¹ã‚³ã‚¢0ã¨ã—ã¦ï¼‰
                        self._notify_progress(
                            progress_callback,
                            f"âš ï¸ {display_id} ã®è©•ä¾¡ä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}"
                        )
                        article.update({
                            "article_id": article_id,  # ä¸€æ„ãªIDã‚’è¿½åŠ 
                            "relevance_score": 0,
                            "is_relevant": False,
                            "relevance_reasoning": f"è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {str(e)}",
                            "depth": depth,
                            "source_pmid": identifier,
                            "source_type": source_type,
                            "mentioned_by": [parent_article_id],  # è¦ªè«–æ–‡ã®IDã‚’è¨˜éŒ²
                            "search_session_id": session_id,  # ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã‚’è¨˜éŒ²
                            "is_newly_evaluated": True  # ã‚¨ãƒ©ãƒ¼ã§ã‚‚è©•ä¾¡ã¯è©¦ã¿ãŸã®ã§True
                        })

                        stats["session_article_count"] += 1  # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚«ã‚¦ãƒ³ãƒˆã‚’å¢—ã‚„ã™

                        # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚ç·Šæ€¥ä¿å­˜
                        if project:
                            project.add_article(article)
                            project.save()
                            self._notify_progress(
                                progress_callback,
                                f"ğŸ’¾ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸãŒã€ã“ã“ã¾ã§ã®é€²æ—ã‚’ä¿å­˜ã—ã¾ã—ãŸ (ä¿å­˜æ¸ˆã¿: {len(collected_articles) + 1}ä»¶)"
                            )

                collected_articles[article_id] = article

                # é–¢é€£æ€§ãŒé«˜ã„è«–æ–‡ã¯æ¬¡ã®éšå±¤ã§æ¢ç´¢
                if article.get("is_relevant"):
                    stats["total_relevant"] += 1
                    # PMIDè«–æ–‡ã‚‚DOIè«–æ–‡ã‚‚æ¬¡ã®éšå±¤ã«è¿½åŠ 
                    # ãŸã ã—ã€DOIè«–æ–‡ã‹ã‚‰ã¯Similar articlesã¯æ¤œç´¢ã§ããªã„ï¼ˆCited by/Referencesã®ã¿ï¼‰
                    next_layer_pmids.append(identifier)
                    if not is_doi_only:
                        print(f"    PMID {identifier} ã‚’æ¬¡ã®éšå±¤ã«è¿½åŠ  (ã‚¹ã‚³ã‚¢: {article.get('relevance_score')})")
                    else:
                        print(f"    DOI {identifier} ã‚’æ¬¡ã®éšå±¤ã«è¿½åŠ  (ã‚¹ã‚³ã‚¢: {article.get('relevance_score')}) â€»Similar articlesã¯é™¤ã")

        print(f"\n[DEBUG] _explore_layer çµ‚äº†")
        print(f"  æ¬¡ã®éšå±¤ã«è¿½åŠ ã™ã‚‹è«–æ–‡æ•°: {len(next_layer_pmids)} ä»¶")
        if next_layer_pmids:
            print(f"  è­˜åˆ¥å­: {next_layer_pmids[:5]}...")

        return next_layer_pmids

    def _notify_progress(
        self,
        callback: Optional[Callable],
        message: str
    ):
        """é€²æ—ã‚’é€šçŸ¥"""
        if callback:
            callback(message)
        else:
            print(message)
